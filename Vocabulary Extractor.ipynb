{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6173adc0",
   "metadata": {},
   "source": [
    "# Vocabulary Extractor\n",
    "\n",
    "Takes a book in English, finds the words that are \"rare\" (by the measure IDF >= 15 or -ln(frequency) > 14) and lists the definition in a dictionary and the places it occurs in the original text. \n",
    "\n",
    "Who is this for?\n",
    " - A casual reader of a book\n",
    " - A teacher trying to teach a book\n",
    " - Students trying to learn vocabulary for a standardized test\n",
    "\n",
    "Features:\n",
    " - Tokenizes the text and words with NLTK to deal with punctuation\n",
    " - Removes proper nouns and character names \n",
    " - Has a lot of custom-built lemmatization (WordNetLemmatizer proved insufficient) to get the root word in order to correctly evaluate rarity AND look up the correct root word in the dictionary\n",
    " - Can easily sort the result by order it appears in the book or overall frequency of the word in the book.\n",
    " - Often dictionary definitions have words that are also hard, so we do a secondary extraction of word meanings in the dictionary definition to make it easy to understand.\n",
    "\n",
    "Could improve:\n",
    " - Doesn't do much for words transliterated from other languages - marks them as vocab words with no dictionary definition.\n",
    " \n",
    "Numbers:\n",
    " - Merriam Webster dictionary has 100k words (102,217)\n",
    " - Word frequency list (en_full) has 1.5m words (1560428) with a total count of ~710m (709588976)\n",
    " - Word frequency list (enwiki) has 1.8m words (1857808) (min count 3) with a totl count of 1.9B (1926212329)\n",
    " - Anecdotally, around 10-15% of unique words of a book will be a vocab word if 15 threshold, 5-10% if 16 threshold.\n",
    " - Anecdotally, around 70% of vocab words have definitions but this number will vary widely. \n",
    " \n",
    " \n",
    "TODO:\n",
    "  - Lemmatize before doing secondary lookup of dictionary definition words e.g. \"tergiversates\"\n",
    "  - Make sure non dict words are written to the vocab   \n",
    "  - Aggregate words which lemmatize to the same word\n",
    "  - Make plugin definition collapsible\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "e6eff90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOOK = 'namesake/namesake.txt'\n",
    "# BOOK = 'midnightschildren/midnightschildren.txt'\n",
    "BOOK = 'shantaram/shantaram.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "dbd45d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/deedy/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/deedy/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "import nltk\n",
    "import string\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import os\n",
    "from pprint import pprint\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict, Counter, namedtuple, OrderedDict\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "3aacc35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_to_lines(fname) -> str:\n",
    "    with open(fname, 'r') as f:\n",
    "        data = f.read()\n",
    "    lines = [d for d in data.split('\\n') if len(d)]\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "68b49618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7944"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = read_to_lines(BOOK)\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2fc850",
   "metadata": {},
   "source": [
    "# Tokenize\n",
    "\n",
    "Tokenize text and grab `word_count` to distil proper nouns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "4674ef7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28675,\n",
       " 21098,\n",
       " Stats(num_lines=7944, num_sentences=28675, num_nonstop_words=208270, num_words=476454, num_chars=2091797, uniq_words=19466, uniq_nonstop_words=19315, pages='1361 pages', time_to_read='31.75 hours', sentences_per_line='3.61', words_per_sentence='16.62', char_per_word='4.39'))"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blacklist = set([p for p in string.punctuation])\n",
    "blacklist = blacklist.union(['``', \"'s\", \"''\", \"'d\", \"n't\", '’', '‘', '…'])\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "WORDS_PER_PAGE = 350\n",
    "WORDS_PER_MINUTE_READING = 250\n",
    "Stats = namedtuple('Stats', [\n",
    "    'num_lines',\n",
    "    'num_sentences',\n",
    "    'num_nonstop_words',\n",
    "    'num_words',\n",
    "    'num_chars',\n",
    "    'uniq_words',\n",
    "    'uniq_nonstop_words',\n",
    "    'pages',\n",
    "    'time_to_read',\n",
    "    'sentences_per_line',\n",
    "    'words_per_sentence',\n",
    "    'char_per_word'\n",
    "])\n",
    "# Returns:\n",
    "# - `sentences`: Tokenize into list of sentences, each containing a list of words\n",
    "# - `word_counts`: Get all word counts (preserving caps) in a Counter\n",
    "# - `stats`: a Stats type containing basic stats about the book\n",
    "def tokenize(lines, ignore_punctuation=True):\n",
    "    num_chars, num_sentences, num_words, num_nonstop_words = 0, 0, 0, 0\n",
    "    sentences = []\n",
    "    word_counts = Counter()\n",
    "    for l in lines:\n",
    "        num_chars += len(l)\n",
    "        for s in nltk.tokenize.sent_tokenize(l):\n",
    "            sen = []\n",
    "            for w in nltk.tokenize.word_tokenize(s):\n",
    "                if ignore_punctuation and not w in blacklist:\n",
    "                    # Someitmes strings like ‘Your aim is off.’ don't tokenize correct.\n",
    "                    if w.endswith('.'):\n",
    "                        w = w[:w.index('.')]\n",
    "                    if w.endswith('…'):\n",
    "                        w = w[:w.index('…')]\n",
    "                sen.append(w)\n",
    "                if w.lower() in stopwords:\n",
    "                    num_nonstop_words += 1\n",
    "            sentences.append(sen)\n",
    "            word_counts.update(sen)\n",
    "            num_words += len(sen)\n",
    "    num_sentences = len(sentences)\n",
    "    uniq_words_set = set([x.lower() for x in word_counts.keys()])\n",
    "    uniq_nonstop_words = len([x for x in uniq_words_set if not x in stopwords])\n",
    "    return sentences, word_counts, Stats(\n",
    "        num_lines=len(lines),\n",
    "        num_sentences=num_sentences,\n",
    "        uniq_words=len(uniq_words_set),\n",
    "        uniq_nonstop_words=uniq_nonstop_words,\n",
    "        num_nonstop_words=num_nonstop_words,\n",
    "        num_words=num_words,\n",
    "        num_chars=num_chars,\n",
    "        pages=f'{int(num_words / WORDS_PER_PAGE)} pages',\n",
    "        time_to_read=f'{int(num_words / WORDS_PER_MINUTE_READING)/60:0.2f} hours',\n",
    "        sentences_per_line=f'{num_sentences/len(lines):0.2f}',\n",
    "        words_per_sentence=f'{num_words/num_sentences:0.2f}',\n",
    "        char_per_word=f'{num_chars/num_words:0.2f}',\n",
    "    )\n",
    "sentences, word_counts, stats = tokenize(lines)\n",
    "len(sentences), len(word_counts), stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c043980c",
   "metadata": {},
   "source": [
    "# Proper Nouns\n",
    "\n",
    "Words that are frequently capitalized are naively marked proper nouns. \n",
    "There may be false positives we don't care about like \"God\", \"I\", \"Mr or words which frequntly start sentences like \"Oh\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "24b126c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('i', 11328),\n",
      " ('karla', 422),\n",
      " ('bombay', 310),\n",
      " ('khaderbhai', 273),\n",
      " ('khaled', 223),\n",
      " ('vikram', 185),\n",
      " ('johnny', 174),\n",
      " ('oh', 166),\n",
      " ('india', 154),\n",
      " ('ulla', 147),\n",
      " ('ghani', 146),\n",
      " ('indian', 145),\n",
      " ('english', 138),\n",
      " ('lisa', 136),\n",
      " ('salman', 131),\n",
      " ('god', 127),\n",
      " ('maurizio', 121),\n",
      " ('hindi', 112),\n",
      " ('ali', 112),\n",
      " ('qasim', 105),\n",
      " ('modena', 103),\n",
      " ('sapna', 103),\n",
      " ('yeah', 102),\n",
      " ('abdul', 101),\n",
      " ('mahmoud', 99),\n",
      " ('lettie', 95),\n",
      " ('habib', 90),\n",
      " ('anand', 89),\n",
      " ('afghan', 87),\n",
      " ('sanjay', 87),\n",
      " ('mr', 83),\n",
      " ('marathi', 83),\n",
      " ('joseph', 78),\n",
      " ('cigar', 75),\n",
      " ('american', 73),\n",
      " ('afghanistan', 71),\n",
      " ('ahmed', 70),\n",
      " ('linbaba', 68),\n",
      " ('tariq', 66),\n",
      " ('prabu', 62),\n",
      " ('kano', 58),\n",
      " ('colaba', 56),\n",
      " ('chuha', 56),\n",
      " ('pakistan', 55),\n",
      " ('farid', 54),\n",
      " ('palace', 53),\n",
      " ('kavita', 52),\n",
      " ('madjid', 51),\n",
      " ('russians', 51),\n",
      " ('jeetendra', 47),\n",
      " ('kandahar', 46),\n",
      " ('german', 45),\n",
      " ('british', 44),\n",
      " ('chapter', 42),\n",
      " ('arthur', 41),\n",
      " ('russian', 41),\n",
      " ('kishan', 39),\n",
      " ('rajan', 37),\n",
      " ('parvati', 37),\n",
      " ('mehta', 36),\n",
      " ('ah', 35),\n",
      " ('goa', 35),\n",
      " ('iran', 35),\n",
      " ('ranjit', 34),\n",
      " ('afghans', 33),\n",
      " ('ansari', 33),\n",
      " ('suleiman', 33),\n",
      " ('rasheed', 32),\n",
      " ('chandra', 32),\n",
      " ('australia', 31),\n",
      " ('hassaan', 31),\n",
      " ('delhi', 29),\n",
      " ('zadeh', 29),\n",
      " ('french', 28),\n",
      " ('rukhmabai', 28),\n",
      " ('zealand', 27),\n",
      " ('hussein', 27),\n",
      " ('allah', 27),\n",
      " ('villu', 27),\n",
      " ('cliff', 27),\n",
      " ('taj', 26),\n",
      " ('krishna', 26),\n",
      " ('muslim', 25),\n",
      " ('raju', 25),\n",
      " ('haji', 25),\n",
      " ('scorpio', 25),\n",
      " ('mahesh', 25),\n",
      " ('andrew', 25),\n",
      " ('iranian', 24),\n",
      " ('hamid', 24),\n",
      " ('melbaaf', 24),\n",
      " ('italian', 23),\n",
      " ('george', 23),\n",
      " ('urdu', 23),\n",
      " ('amir', 23),\n",
      " ('jalalaad', 22),\n",
      " ('gemini', 21),\n",
      " ('faisal', 21),\n",
      " ('australian', 20),\n",
      " ('rajubhai', 20),\n",
      " ('kumar', 20),\n",
      " ('obikwa', 19),\n",
      " ('quetta', 19),\n",
      " ('jesus', 18),\n",
      " ('causeway', 18),\n",
      " ('fort', 18),\n",
      " ('sunder', 18),\n",
      " ('satish', 18),\n",
      " ('maria', 18),\n",
      " ('carter', 18),\n",
      " ('shantu', 17),\n",
      " ('radha', 17),\n",
      " ('raj', 17),\n",
      " ('raheem', 17),\n",
      " ('rahul', 17),\n",
      " ('rao', 17),\n",
      " ('hindu', 16),\n",
      " ('lindsay', 16),\n",
      " ('states', 16),\n",
      " ('koran', 16),\n",
      " ('bollywood', 16),\n",
      " ('ameer', 16),\n",
      " ('sri', 16),\n",
      " ('gateway', 15),\n",
      " ('germany', 15),\n",
      " ('borsalino', 15),\n",
      " ('sikh', 15),\n",
      " ('massoud', 15),\n",
      " ('muslims', 14),\n",
      " ('vinod', 14),\n",
      " ('singh', 14),\n",
      " ('marine', 14),\n",
      " ('sobhan', 14),\n",
      " ('kalpana', 14),\n",
      " ('karachi', 14),\n",
      " ('canadian', 13),\n",
      " ('deshpande', 13),\n",
      " ('african', 13),\n",
      " ('america', 13),\n",
      " ('crawford', 13),\n",
      " ('taheri', 13),\n",
      " ('inshallah', 13),\n",
      " ('arabic', 13),\n",
      " ('prophet', 13),\n",
      " ('gilbert', 13),\n",
      " ('palestinian', 13),\n",
      " ('sita', 13),\n",
      " ('georges', 13),\n",
      " ('indira', 13),\n",
      " ('souza', 13),\n",
      " ('singapore', 12),\n",
      " ('maharashtrian', 12),\n",
      " ('nevertheless', 12),\n",
      " ('ramesh', 12),\n",
      " ('nariman', 12),\n",
      " ('parker', 12),\n",
      " ('mustaan', 12),\n",
      " ('ayub', 12),\n",
      " ('mohammed', 12),\n",
      " ('kabul', 12),\n",
      " ('maharashtra', 11),\n",
      " ('european', 11),\n",
      " ('rafiq', 11),\n",
      " ('jewish', 11),\n",
      " ('americans', 11),\n",
      " ('gandhi', 11),\n",
      " ('arrey', 11),\n",
      " ('gulf', 11),\n",
      " ('regal', 11),\n",
      " ('t-shirt', 11),\n",
      " ('naresh', 11),\n",
      " ('de', 11),\n",
      " ('shah', 11),\n",
      " ('christian', 10),\n",
      " ('york', 10),\n",
      " ('kharre', 10),\n",
      " ('u-huh', 10),\n",
      " ('kinshasa', 10),\n",
      " ('europe', 10),\n",
      " ('flora', 10),\n",
      " ('st', 10),\n",
      " ('faroukh', 10),\n",
      " ('raghuram', 10),\n",
      " ('pashto', 10),\n",
      " ('akbar', 10),\n",
      " ('nigerian', 10),\n",
      " ('mukul', 10),\n",
      " ('gupta-ji', 10),\n",
      " ('pakistani', 10),\n",
      " ('kalashnikov', 10),\n",
      " ('siddiqi', 10),\n",
      " ('hanif', 10),\n",
      " ('roberts', 9),\n",
      " ('canada', 9),\n",
      " ('africans', 9),\n",
      " ('spaniard', 9),\n",
      " ('swiss', 9),\n",
      " ('sikhs', 9),\n",
      " ('africa', 9),\n",
      " ('tardeo', 9),\n",
      " ('goan', 9),\n",
      " ('enfield', 9),\n",
      " ('achakzai', 9),\n",
      " ('mackenzie', 9),\n",
      " ('esquire', 9),\n",
      " ('rahman', 9),\n",
      " ('juma', 9),\n",
      " ('lanka', 9),\n",
      " ('chowpatty', 8),\n",
      " ('france', 8),\n",
      " ('sena', 8),\n",
      " ('arabian', 8),\n",
      " ('dongri', 8),\n",
      " ('london', 8),\n",
      " ('nagar', 8),\n",
      " ('dilip', 8),\n",
      " ('bible', 8),\n",
      " ('italy', 8),\n",
      " ('ned', 8),\n",
      " ('gulab', 8),\n",
      " ('jeet', 8),\n",
      " ('ganesha', 8),\n",
      " ('tony', 8),\n",
      " ('idriss', 8),\n",
      " ('canadians', 7),\n",
      " ('asia', 7),\n",
      " ('europeans', 7),\n",
      " ('switzerland', 7),\n",
      " ('marseilles', 7),\n",
      " ('walidlalla', 7),\n",
      " ('iranians', 7),\n",
      " ('iraq', 7),\n",
      " ('sassoon', 7),\n",
      " ('christina', 7),\n",
      " ('greek', 7),\n",
      " ('zodiac', 7),\n",
      " ('abdur', 7),\n",
      " ('saaranen', 6),\n",
      " ('thik', 6),\n",
      " ('moreover', 6),\n",
      " ('mumbai', 6),\n",
      " ('nigerians', 6),\n",
      " ('italians', 6),\n",
      " ('biarritz', 6),\n",
      " ('patel', 6),\n",
      " ('challo', 6),\n",
      " ('ambassador', 6),\n",
      " ('bhagwan', 6),\n",
      " ('omar', 6),\n",
      " ('ranjitbhai', 6),\n",
      " ('khyber', 6),\n",
      " ('chinese', 6),\n",
      " ('peshawar', 6),\n",
      " ('patak', 6),\n",
      " ('mapusa', 6),\n",
      " ('thus', 6),\n",
      " ('faloodah', 6),\n",
      " ('asmatullah', 6),\n",
      " ('chota', 6),\n",
      " ('stechkin', 6),\n",
      " ('stingers', 6),\n",
      " ('ala-ud-din', 6),\n",
      " ('savak', 6),\n",
      " ('rakeshbaba', 6),\n",
      " ('ganesh', 6),\n",
      " ('tamil', 5),\n",
      " ('buddhist', 5),\n",
      " ('parsee', 5),\n",
      " ('christ', 5),\n",
      " ('buddha', 5),\n",
      " ('basel', 5),\n",
      " ('shiv', 5),\n",
      " ('hindus', 5),\n",
      " ('lagos', 5),\n",
      " ('them—i', 5),\n",
      " ('mahatma', 5),\n",
      " ('federico', 5),\n",
      " ('spanish', 5),\n",
      " ('clint', 5),\n",
      " ('sarr', 5),\n",
      " ('nabila', 5),\n",
      " ('bandra', 5),\n",
      " ('christians', 5),\n",
      " ('zhaveri', 5),\n",
      " ('veejay', 5),\n",
      " ('kishore', 5),\n",
      " ('gim', 5),\n",
      " ('congress', 5),\n",
      " ('keki', 5),\n",
      " ('ferreira', 5),\n",
      " ('hannibal', 5),\n",
      " ('shatila', 5),\n",
      " ('oui', 5),\n",
      " ('alors', 5),\n",
      " ('mrs', 5),\n",
      " ('saurabh', 5),\n",
      " ('juhu', 5),\n",
      " ('kelly', 5),\n",
      " ('genova', 5),\n",
      " ('sweden', 5),\n",
      " ('kimi', 5),\n",
      " ('anwar', 5),\n",
      " ('geeta', 5),\n",
      " ('tajik', 5),\n",
      " ('farsi', 5),\n",
      " ('isi', 5),\n",
      " ('shar-i-safa', 5),\n",
      " ('patil', 5),\n",
      " ('queen', 5),\n",
      " ('indra', 5),\n",
      " ('rajasthan', 4),\n",
      " ('varanasi', 4),\n",
      " ('maharashtrians', 4),\n",
      " ('kuwait', 4),\n",
      " ('mocambo', 4),\n",
      " ('shakespeare', 4),\n",
      " ('eastwood', 4),\n",
      " ('registration', 4),\n",
      " ('belgian', 4),\n",
      " ('c-form', 4),\n",
      " ('cuffe', 4),\n",
      " ('khaderji', 4),\n",
      " ('kashmiri', 4),\n",
      " ('iqbal', 4),\n",
      " ('ram', 4),\n",
      " ('municipal', 4),\n",
      " ('corporation', 4),\n",
      " ('wow', 4),\n",
      " ('fiat', 4),\n",
      " ('romans', 4),\n",
      " ('deutschmarks', 4),\n",
      " ('rolex', 4),\n",
      " ('nandita', 4),\n",
      " ('noonday', 4),\n",
      " ('u', 4),\n",
      " ('arab', 4),\n",
      " ('bluestar', 4),\n",
      " ('churchgate', 4),\n",
      " ('jew', 4),\n",
      " ('bang', 4),\n",
      " ('dashrant', 4),\n",
      " ('lankan', 4),\n",
      " ('belcane', 4),\n",
      " ('aaja', 4),\n",
      " ('mauritius', 4),\n",
      " ('mauritian', 4),\n",
      " ('oberoi', 4),\n",
      " ('reeta', 4),\n",
      " ('mifune', 4),\n",
      " ('soviet', 4),\n",
      " ('pashtun', 4),\n",
      " ('ak-74', 4),\n",
      " ('algerian', 4),\n",
      " ('shahbadi', 4),\n",
      " ('khomeini', 4),\n",
      " ('jeetudada', 4),\n",
      " ('walid', 4),\n",
      " ('saatch', 4),\n",
      " ('arturo', 4),\n",
      " ('choudry', 4),\n",
      " ('assamese', 3),\n",
      " ('bengal', 3),\n",
      " ('interpol', 3),\n",
      " ('arabs', 3),\n",
      " ('o-kay', 3),\n",
      " ('ajanta', 3),\n",
      " ('naja', 3),\n",
      " ('ajay', 3),\n",
      " ('parsees', 3),\n",
      " ('punjab', 3),\n",
      " ('kashmir', 3),\n",
      " ('germans', 3),\n",
      " ('victoria', 3),\n",
      " ('it—i', 3),\n",
      " ('me—i', 3),\n",
      " ('saudi', 3),\n",
      " ('england', 3),\n",
      " ('denmark', 3),\n",
      " ('copenhagen', 3),\n",
      " ('zapata', 3),\n",
      " ('ciao', 3),\n",
      " ('swedish', 3),\n",
      " ('right—i', 3),\n",
      " ('v.t', 3),\n",
      " ('bangladesh', 3),\n",
      " ('australians', 3),\n",
      " ('aurangabad', 3),\n",
      " ('pandey', 3),\n",
      " ('amitabh', 3),\n",
      " ('kalaass', 3),\n",
      " ('sufi', 3),\n",
      " ('mecca', 3),\n",
      " ('nana', 3),\n",
      " ('chowk', 3),\n",
      " ('pasta', 3),\n",
      " ('khar', 3),\n",
      " ('april', 3),\n",
      " ('uttar', 3),\n",
      " ('pradesh', 3),\n",
      " ('saap', 3),\n",
      " ('achaa', 3),\n",
      " ('compton', 3),\n",
      " ('jack', 3),\n",
      " ('palestine', 3),\n",
      " ('dorabjee', 3),\n",
      " ('fattah', 3),\n",
      " ('eve-teasing', 3),\n",
      " ('andheri', 3),\n",
      " ('sandeep', 3),\n",
      " ('jyoti', 3),\n",
      " ('mario', 3),\n",
      " ('mahim', 3),\n",
      " ('bunder', 3),\n",
      " ('santosh', 3),\n",
      " ('dubai', 3),\n",
      " ('candy', 3),\n",
      " ('bhindranwale', 3),\n",
      " ('lakshmi', 3),\n",
      " ('israelis', 3),\n",
      " ('rhustem', 3),\n",
      " ('portuguese', 3),\n",
      " ('slum—i', 3),\n",
      " ('xavier', 3),\n",
      " ('jesuits', 3),\n",
      " ('vietnam', 3),\n",
      " ('athens', 3),\n",
      " ('siddhartha', 3),\n",
      " ('sadiq', 3),\n",
      " ('rinaldo', 3),\n",
      " ('whaddaya', 3),\n",
      " ('zaire', 3),\n",
      " ('mobutu', 3),\n",
      " ('r', 3),\n",
      " ('chunkey', 3),\n",
      " ('dadar', 3),\n",
      " ('christine', 3),\n",
      " ('bohri', 3),\n",
      " ('cia', 3),\n",
      " ('scotland', 3),\n",
      " ('stinger', 3),\n",
      " ('shahbad', 3),\n",
      " ('ak-47', 3),\n",
      " ('bobs', 3),\n",
      " ('zaher', 3),\n",
      " ('rasul', 3),\n",
      " ('hazarbuz', 3),\n",
      " ('pk', 3),\n",
      " ('sayeed', 3),\n",
      " ('kishmishi', 3),\n",
      " ('alice', 3),\n",
      " ('thana', 3),\n",
      " ('wildlife', 3),\n",
      " ('ganpatti', 3),\n",
      " ('obstacles', 3),\n",
      " ('david', 2),\n",
      " ('punjabis', 2),\n",
      " ('konarak', 2),\n",
      " ('zealanders', 2),\n",
      " ('melbourne', 2),\n",
      " ('himalayas', 2),\n",
      " ('manali', 2),\n",
      " ('poona', 2),\n",
      " ('irish', 2),\n",
      " ('hmmm', 2),\n",
      " ('karla—she', 2),\n",
      " ('walkman', 2),\n",
      " ('elephanta', 2),\n",
      " ('thai-white', 2),\n",
      " ('scheisse', 2),\n",
      " ('sainiks', 2),\n",
      " ('nigeria', 2),\n",
      " ('i—we', 2),\n",
      " ('atlantic', 2),\n",
      " ('karma', 2),\n",
      " ('suresh', 2),\n",
      " ('words—i', 2),\n",
      " ('pune', 2),\n",
      " ('orissa', 2),\n",
      " ('arabia', 2),\n",
      " ('milano', 2),\n",
      " ('frenchman', 2),\n",
      " ('japan', 2),\n",
      " ('mondegar', 2),\n",
      " ('frenchmen', 2),\n",
      " ('bah', 2),\n",
      " ('jehangir', 2),\n",
      " ('bonne', 2),\n",
      " ('jamner', 2),\n",
      " ('narayan', 2),\n",
      " ('bharat', 2),\n",
      " ('deepakbhai', 2),\n",
      " ('apsara', 2),\n",
      " ('bachchan', 2),\n",
      " ('doc', 2),\n",
      " ('cpr', 2),\n",
      " ('slot', 2),\n",
      " ('whores', 2),\n",
      " ('ramu', 2),\n",
      " ('persian', 2),\n",
      " ('shafiq', 2),\n",
      " ('nagpur', 2),\n",
      " ('buddhists', 2),\n",
      " ('jains', 2),\n",
      " ('aap', 2),\n",
      " ('b', 2),\n",
      " ('v', 2),\n",
      " ('sunil', 2),\n",
      " ('fatimah', 2),\n",
      " ('qasimbhai', 2),\n",
      " ('andhkaara', 2),\n",
      " ('sunita', 2),\n",
      " ('tamils', 2),\n",
      " ('karnatakans', 2),\n",
      " ('t-shirts', 2),\n",
      " ('kgb', 2),\n",
      " ('karla—what', 2),\n",
      " ('lewis', 2),\n",
      " ('carrolls', 2),\n",
      " ('englishman', 2),\n",
      " ('hussein—you', 2),\n",
      " ('ash-hadu', 2),\n",
      " ('ila', 2),\n",
      " ('frustrated', 2),\n",
      " ('zuhr', 2),\n",
      " ('alps', 2),\n",
      " ('schiller', 2),\n",
      " ('oxford', 2),\n",
      " ('marx', 2),\n",
      " ('crusades', 2),\n",
      " ('koranic', 2),\n",
      " ('ford', 2),\n",
      " ('et', 2),\n",
      " ('chandrika', 2),\n",
      " ('jeetu', 2),\n",
      " ('ort', 2),\n",
      " ('orts', 2),\n",
      " ('rohde', 2),\n",
      " ('anna', 2),\n",
      " ('fabian', 2),\n",
      " ('oooooh', 2),\n",
      " ('malhotra', 2),\n",
      " ('israel', 2),\n",
      " ('tunisia', 2),\n",
      " ('syria', 2),\n",
      " ('abu', 2),\n",
      " ('dhabi', 2),\n",
      " ('bahrain', 2),\n",
      " ('marathis', 2),\n",
      " ('amritsar', 2),\n",
      " ('mumbaiker', 2),\n",
      " ('bombayite', 2),\n",
      " ('israeli', 2),\n",
      " ('october', 2),\n",
      " ('sharif', 2),\n",
      " ('sten', 2),\n",
      " ('story—i', 2),\n",
      " ('here—i', 2),\n",
      " ('panjim', 2),\n",
      " ('friday', 2),\n",
      " ('chapora', 2),\n",
      " ('anjuna', 2),\n",
      " ('francis', 2),\n",
      " ('tv', 2),\n",
      " ('usa', 2),\n",
      " ('emiliano', 2),\n",
      " ('lankans', 2),\n",
      " ('jaffna', 2),\n",
      " ('americas', 2),\n",
      " ('venezuela', 2),\n",
      " ('congratulations', 2),\n",
      " ('delhi-side', 2),\n",
      " ('vasant', 2),\n",
      " ('lai', 2),\n",
      " ('britain', 2),\n",
      " ('dutch', 2),\n",
      " ('calcutta', 2),\n",
      " ('madras', 2),\n",
      " ('katkar', 2),\n",
      " ('sebastian', 2),\n",
      " ('john', 2),\n",
      " ('sajan', 2),\n",
      " ('konkani', 2),\n",
      " ('anil', 2),\n",
      " ('versova', 2),\n",
      " ('mehmet', 2),\n",
      " ('funny—i', 2),\n",
      " ('shilpa', 2),\n",
      " ('sahara', 2),\n",
      " ('toshiro', 2),\n",
      " ('november', 2),\n",
      " ('uzbek', 2),\n",
      " ('mao', 2),\n",
      " ('lenin', 2),\n",
      " ('hekmatyar', 2),\n",
      " ('pakistanis', 2),\n",
      " ('durrani', 2),\n",
      " ('gulabji', 2),\n",
      " ('yaaru', 2),\n",
      " ('kaarez', 2),\n",
      " ('herat', 2),\n",
      " ('solomon', 2),\n",
      " ('mig', 2),\n",
      " ('pathaan', 2),\n",
      " ('asalaam', 2),\n",
      " ('russia', 2),\n",
      " ('bertrand', 2),\n",
      " ('russell', 2),\n",
      " ('ee-allah', 2),\n",
      " ('arghandab', 2),\n",
      " ('kalashnikovs', 2),\n",
      " ('hitler', 2),\n",
      " ('schmeisser', 2),\n",
      " ('frederick', 2),\n",
      " ('gupta', 2),\n",
      " ('la', 2),\n",
      " ('ghazni', 2),\n",
      " ('dari', 2),\n",
      " ('alef', 2),\n",
      " ('her—i', 2),\n",
      " ('ayatollah', 2),\n",
      " ('revenge—i', 2),\n",
      " ('abdulbhai', 2),\n",
      " ('ballard', 2),\n",
      " ('fixer', 2),\n",
      " ('mahalaxmi', 2),\n",
      " ('ashok', 2),\n",
      " ('y-shaped', 2),\n",
      " ('mehta-de', 2),\n",
      " ('wildlife-wallahs', 2),\n",
      " ('sapna-iran', 2),\n",
      " ('sapnas', 2),\n",
      " ('chaku', 2),\n",
      " ('lin', 1),\n",
      " ('prabaker', 1),\n",
      " ('khader', 1),\n",
      " ('abdullah', 1),\n",
      " ('didier', 1),\n",
      " ('nazeer', 1),\n",
      " ('madame', 1),\n",
      " ('khan', 1),\n",
      " ('zhou', 1),\n",
      " ('leopold', 1),\n",
      " ('abdel', 1),\n",
      " ('indians', 1),\n",
      " ('babas', 1),\n",
      " ('chaman', 1),\n",
      " ('letitia', 1),\n",
      " ('shantaram', 1),\n",
      " ('levy', 1),\n",
      " ('gregory', 1),\n",
      " ('jats', 1),\n",
      " ('nadu', 1),\n",
      " ('pushkar', 1),\n",
      " ('cochin', 1),\n",
      " ('brahmin', 1),\n",
      " ('jain', 1),\n",
      " ('animist', 1),\n",
      " ('mules', 1),\n",
      " ('auckland', 1),\n",
      " ('malabar', 1),\n",
      " ('kerala', 1),\n",
      " ('rajneeshis', 1),\n",
      " ('gotham', 1),\n",
      " ('rio', 1),\n",
      " ('paris', 1),\n",
      " ('god-damn', 1),\n",
      " ('buddy—i', 1),\n",
      " ('shield—apsara', 1),\n",
      " ('hotel—indicating', 1),\n",
      " ('bailey', 1),\n",
      " ('neapolitan', 1),\n",
      " ('noooo', 1),\n",
      " ('besides', 1),\n",
      " ('johnnie', 1),\n",
      " ('walker', 1),\n",
      " ('trash', 1),\n",
      " ('raj-romantic', 1),\n",
      " ('craning', 1),\n",
      " ('sanskrit', 1),\n",
      " ('lindsay—that', 1),\n",
      " ('girl—karla', 1),\n",
      " ('hike', 1),\n",
      " ('name—lin—is', 1),\n",
      " ('berlin', 1),\n",
      " ('became—linbaba—was', 1),\n",
      " ('now—oh', 1),\n",
      " ('proprietor', 1),\n",
      " ('afghani', 1),\n",
      " ('did—i', 1),\n",
      " ('helvetian', 1),\n",
      " ('swiss-american', 1),\n",
      " ('ellora', 1),\n",
      " ('zurich', 1),\n",
      " ('knew—i', 1),\n",
      " ('basel—have', 1),\n",
      " ('rhine', 1),\n",
      " ('jaldi', 1),\n",
      " ('salut', 1),\n",
      " ('spinner', 1),\n",
      " ('klamotten', 1),\n",
      " ('sprintficker', 1),\n",
      " ('spritzen', 1),\n",
      " ('gibt', 1),\n",
      " ('schwanz', 1),\n",
      " ('schuhe', 1),\n",
      " ('tschus', 1),\n",
      " ('what—does', 1),\n",
      " ('lacoste', 1),\n",
      " ('cardin', 1),\n",
      " ('cartier', 1),\n",
      " ('privileged', 1),\n",
      " ('flashbacks', 1),\n",
      " ('bairam', 1),\n",
      " ('mmm', 1),\n",
      " ('someone—you', 1),\n",
      " ('hatchet', 1),\n",
      " ('sainiks—oh', 1),\n",
      " ('admirable', 1),\n",
      " ('khader-elder', 1),\n",
      " ('khaderbhai—he', 1),\n",
      " ('him—i', 1),\n",
      " ('english—the', 1),\n",
      " ('mahal—not', 1),\n",
      " ('greeks', 1),\n",
      " ('bombay—indians', 1),\n",
      " ('simoom', 1),\n",
      " ('sainiks—or', 1),\n",
      " ('moroccan', 1),\n",
      " ('indians—and', 1),\n",
      " ('katzeli', 1),\n",
      " ('it—didier', 1),\n",
      " ('yours—i', 1),\n",
      " ('what—that', 1),\n",
      " ('pacific', 1),\n",
      " ('american—at', 1),\n",
      " ('london—twice', 1),\n",
      " ('india—she', 1),\n",
      " ('byron', 1),\n",
      " ('wife—i', 1),\n",
      " ('mughlai', 1),\n",
      " ('catiline', 1),\n",
      " ('landmarks—flora', 1),\n",
      " ('vt', 1),\n",
      " ('market—we', 1),\n",
      " ('hindi—what', 1),\n",
      " ('mujhako', 1),\n",
      " ('baapree', 1),\n",
      " ('desh', 1),\n",
      " ('ata', 1),\n",
      " ('colabala', 1),\n",
      " ('kaigaram', 1),\n",
      " ('haryana', 1),\n",
      " ('sourced', 1),\n",
      " ('contacting', 1),\n",
      " ('schools—boys', 1),\n",
      " ('centres—when', 1),\n",
      " ('virgil', 1),\n",
      " ('aaaaah', 1),\n",
      " ('milan', 1),\n",
      " ('borsalinos', 1),\n",
      " ('comme', 1),\n",
      " ('right—prabaker', 1),\n",
      " ('norway', 1),\n",
      " ('touché', 1),\n",
      " ('federico—three', 1),\n",
      " ('wirklich', 1),\n",
      " ('danes', 1),\n",
      " ('vikkie', 1),\n",
      " ('sergio', 1),\n",
      " ('leone', 1),\n",
      " ('mmmmm—no', 1),\n",
      " ('artagnan', 1),\n",
      " ('merci', 1),\n",
      " ('allora', 1),\n",
      " ('ray-ban', 1),\n",
      " ('drifter', 1),\n",
      " ('madonna', 1),\n",
      " ('un-french', 1),\n",
      " ('federico—you', 1),\n",
      " ('imtiaz', 1),\n",
      " ('dharker', 1),\n",
      " ('not—i', 1),\n",
      " ('platforms', 1),\n",
      " ('vt.—was', 1),\n",
      " ('buddha—beg', 1),\n",
      " ('were—i', 1),\n",
      " ('english—i', 1),\n",
      " ('tibet', 1),\n",
      " ('jalgaon', 1),\n",
      " ('chalisgao', 1),\n",
      " ('bedford', 1),\n",
      " ('deccan', 1),\n",
      " ('panic—yaaah', 1),\n",
      " ('yaaah', 1),\n",
      " ('amazon', 1),\n",
      " ('gaee', 1),\n",
      " ('louis', 1),\n",
      " ('pasteur', 1),\n",
      " ('monsieur', 1),\n",
      " ('assembling', 1),\n",
      " ('paous', 1),\n",
      " ('natinkerra', 1),\n",
      " ('sang—i', 1),\n",
      " ('kinks', 1),\n",
      " ('theresa', 1),\n",
      " ('mataji', 1),\n",
      " ('sunder—they', 1),\n",
      " ('foreigner—german', 1),\n",
      " ('overstaying', 1),\n",
      " ('c-forms', 1),\n",
      " ('byculla', 1),\n",
      " ('kashmiri—the', 1),\n",
      " ('horrible—that', 1),\n",
      " ('anand—the', 1),\n",
      " ('unresisting', 1),\n",
      " ('minutes—i', 1),\n",
      " ('sarabai', 1),\n",
      " ('bas', 1),\n",
      " ('lin-shantaram', 1),\n",
      " ('unplastered', 1),\n",
      " ('mister-fuckin', 1),\n",
      " ('-negative', 1),\n",
      " ('heartened', 1),\n",
      " ('v-shaped', 1),\n",
      " ('sadhus', 1),\n",
      " ('lunatics', 1),\n",
      " ('come—sit', 1),\n",
      " ('vip', 1),\n",
      " ('ramu—there', 1),\n",
      " ('persian—sometimes', 1),\n",
      " ('gussa', 1),\n",
      " ('jeebies', 1),\n",
      " ('canon', 1),\n",
      " ('thar', 1),\n",
      " ('abdullah—you', 1),\n",
      " ('bhatia', 1),\n",
      " ('sheik', 1),\n",
      " ('funded', 1),\n",
      " ('f', 1),\n",
      " ('w', 1),\n",
      " ('bahut', 1),\n",
      " ('god—anyone', 1),\n",
      " ('god—and', 1),\n",
      " ('raghu', 1),\n",
      " ('arthritis', 1),\n",
      " ('shaila', 1),\n",
      " ('najimah', 1),\n",
      " ('ow-ah', 1),\n",
      " ('froth', 1),\n",
      " ('takleef', 1),\n",
      " ('mind—kano', 1),\n",
      " ('aha', 1),\n",
      " ('gujaratis', 1),\n",
      " ('trivandrum', 1),\n",
      " ('bikaner', 1),\n",
      " ('cigar—a', 1),\n",
      " ('aseef', 1),\n",
      " ('enlightened', 1),\n",
      " ('poonam', 1),\n",
      " ('prakash', 1),\n",
      " ('parle', 1),\n",
      " ('gluco', 1),\n",
      " ('entrepreneurs', 1),\n",
      " ('yeah—do', 1),\n",
      " ('men—prabaker', 1),\n",
      " ('hussein—regarded', 1),\n",
      " ('concreting', 1),\n",
      " ('everest', 1),\n",
      " ('american-accented', 1),\n",
      " ('pagal', 1),\n",
      " ('not-smiling', 1),\n",
      " ('radha—she', 1),\n",
      " ('yes—have', 1),\n",
      " ('b.m.c', 1),\n",
      " ('devious', 1),\n",
      " ('bumblebee', 1),\n",
      " ('accident—i', 1),\n",
      " ('answer—i', 1),\n",
      " ('joan', 1),\n",
      " ('sledge', 1),\n",
      " ('bombay—with', 1),\n",
      " ('william', 1),\n",
      " ('morris', 1),\n",
      " ('parker—have', 1),\n",
      " ('parker-in-love', 1),\n",
      " ('remember—lisa', 1),\n",
      " ('natürlich', 1),\n",
      " ('posters—lauren', 1),\n",
      " ('bacall', 1),\n",
      " ('angeli', 1),\n",
      " ('sean', 1),\n",
      " ('californian', 1),\n",
      " ('nutcase', 1),\n",
      " ('swiss-german', 1),\n",
      " ('freeway', 1),\n",
      " ('it—please', 1),\n",
      " ('isfahan', 1),\n",
      " ('kaaba', 1),\n",
      " ('mahmoud—let', 1),\n",
      " ('varanasi—have', 1),\n",
      " ('zanzibar', 1),\n",
      " ('gujarat', 1),\n",
      " ('teheran', 1),\n",
      " ('me—andrew', 1),\n",
      " ('bombay—but', 1),\n",
      " ('bbc-accented', 1),\n",
      " ('sapna—or', 1),\n",
      " ('christian—just', 1),\n",
      " ('sermon', 1),\n",
      " ('ganges', 1),\n",
      " ('majidbhai', 1),\n",
      " ('achaa-cha', 1),\n",
      " ('the—how', 1),\n",
      " ('uncle-ji', 1),\n",
      " ('comment—i', 1),\n",
      " ('dorabji', 1),\n",
      " ('shuba', 1),\n",
      " ('badly-drinking-joseph', 1),\n",
      " ('goodnight', 1),\n",
      " ('puma', 1),\n",
      " ('chrissakes', 1),\n",
      " ('dadung', 1),\n",
      " ('marathi—it', 1),\n",
      " ('mahabharata', 1),\n",
      " ('peaces', 1),\n",
      " ('ji', 1),\n",
      " ('street—but', 1),\n",
      " ('englishmen', 1),\n",
      " ('idhar-ao', 1),\n",
      " ('yesterday—i', 1),\n",
      " ('lin—you', 1),\n",
      " ('farishta', 1),\n",
      " ('—if', 1),\n",
      " ('self-disgust', 1),\n",
      " ('pliancy—how', 1),\n",
      " ('daniels', 1),\n",
      " ('six-teen', 1),\n",
      " ('carthaginian', 1),\n",
      " ('rome', 1),\n",
      " ('stendhal', 1),\n",
      " ('charterhouse', 1),\n",
      " ('parma', 1),\n",
      " ('bovary', 1),\n",
      " ('thomas', 1),\n",
      " ('mann', 1),\n",
      " ('djuna', 1),\n",
      " ('barnes', 1),\n",
      " ('virginia', 1),\n",
      " ('woolf', 1),\n",
      " ('maldoror', 1),\n",
      " ('isidore', 1),\n",
      " ('ducasse', 1),\n",
      " ('gogol', 1),\n",
      " ('prominently', 1),\n",
      " ('durga', 1),\n",
      " ('recognising', 1),\n",
      " ('sapna—i', 1),\n",
      " ('snuggling', 1),\n",
      " ('friends—khaderbhai', 1),\n",
      " ('l-shape', 1),\n",
      " ('rococo', 1),\n",
      " ('beat—i', 1),\n",
      " ('name—hassaan', 1),\n",
      " ('appraising', 1),\n",
      " ('rose—then', 1),\n",
      " ('prabaker—was', 1),\n",
      " ('maori', 1),\n",
      " ('exactly—merde', 1),\n",
      " ('vikram—he', 1),\n",
      " ('news—kavita', 1),\n",
      " ('snatcher', 1),\n",
      " ('jamais', 1),\n",
      " ('tariq—missing', 1),\n",
      " ('already—i', 1),\n",
      " ('feeling—i', 1),\n",
      " ('earth—the', 1),\n",
      " ('hold—i', 1),\n",
      " ('kandivli', 1),\n",
      " ('thane—more', 1),\n",
      " ('therapy', 1),\n",
      " ('jon', 1),\n",
      " ('unicef', 1),\n",
      " ('swiss-italian', 1),\n",
      " ('ischa', 1),\n",
      " ('san', 1),\n",
      " ('francisco', 1),\n",
      " ('pacelli', 1),\n",
      " ('penelope', 1),\n",
      " ('los', 1),\n",
      " ('angeles', 1),\n",
      " ('zhou—i', 1),\n",
      " ('romeo', 1),\n",
      " ('juliet', 1),\n",
      " ('yemeni', 1),\n",
      " ('somalis', 1),\n",
      " ('european—had', 1),\n",
      " ('cuban-heeled', 1),\n",
      " ('arre', 1),\n",
      " ('seedha', 1),\n",
      " ('mereweather', 1),\n",
      " ('egyptian', 1),\n",
      " ('transients', 1),\n",
      " ('imbued', 1),\n",
      " ('challol', 1),\n",
      " ('inmates', 1),\n",
      " ('pandu', 1),\n",
      " ('advancing', 1),\n",
      " ('aiming', 1),\n",
      " ('sundays', 1),\n",
      " ('bulfinch', 1),\n",
      " ('mythology', 1),\n",
      " ('despotism', 1),\n",
      " ('sunday', 1),\n",
      " ('patel—sitting', 1),\n",
      " ('mexican', 1),\n",
      " ('dettol', 1),\n",
      " ('bombay—she', 1),\n",
      " ('australia—it', 1),\n",
      " ('bombay—you', 1),\n",
      " ('ok', 1),\n",
      " ('cows—i', 1),\n",
      " ('lebanon', 1),\n",
      " ('libya', 1),\n",
      " ('lin—yours', 1),\n",
      " ('americanisms', 1),\n",
      " ('muscat', 1),\n",
      " ('assyria', 1),\n",
      " ('akkad', 1),\n",
      " ('sumer', 1),\n",
      " ('babylon', 1),\n",
      " ('ranjit—he', 1),\n",
      " ('mother—khaled', 1),\n",
      " ('spartan', 1),\n",
      " ('gangsters—salman', 1),\n",
      " ('zen', 1),\n",
      " ('kingfisher', 1),\n",
      " ('australia—he', 1),\n",
      " ('klf', 1),\n",
      " ('guys—i', 1),\n",
      " ('selfishly', 1),\n",
      " ('khalistan', 1),\n",
      " ('tiger—you—was', 1),\n",
      " ('yaar—i', 1),\n",
      " ('vikram—whatever', 1),\n",
      " ('denmark—', 1),\n",
      " ('toto', 1),\n",
      " ('yeah—you', 1),\n",
      " ('patak—thanks', 1),\n",
      " ('sardarji', 1),\n",
      " ('christmas', 1),\n",
      " ('sabra', 1),\n",
      " ('jews—they', 1),\n",
      " ('war—the', 1),\n",
      " ('yom', 1),\n",
      " ('kippur', 1),\n",
      " ('tunis', 1),\n",
      " ('beirut', 1),\n",
      " ('phalange', 1),\n",
      " ('holocaust', 1),\n",
      " ('mt', 1),\n",
      " ('scopus', 1),\n",
      " ('lin—', 1),\n",
      " ('nicholas', 1),\n",
      " ('years—i', 1),\n",
      " ('namaste', 1),\n",
      " ('rajiv—an', 1),\n",
      " ('accordingly', 1),\n",
      " ('australia—was', 1),\n",
      " ('australia—and', 1),\n",
      " ('painful—i', 1),\n",
      " ('india—why', 1),\n",
      " ('factories', 1),\n",
      " ('god-and-heaven', 1),\n",
      " ('platinum', 1),\n",
      " ('iridium', 1),\n",
      " ('frankfurt', 1),\n",
      " ('johannesburg', 1),\n",
      " ('transact', 1),\n",
      " ('kranti', 1),\n",
      " ('marg', 1),\n",
      " ('indians—from', 1),\n",
      " ('roman', 1),\n",
      " ('enfields', 1),\n",
      " ('liverpool', 1),\n",
      " ('lin—what', 1),\n",
      " ('freud', 1),\n",
      " ('adler', 1),\n",
      " ('victor', 1),\n",
      " ('frankl', 1),\n",
      " ('muppsa', 1),\n",
      " ('calangute', 1),\n",
      " ('shiva', 1),\n",
      " ('rama', 1),\n",
      " ('colva', 1),\n",
      " ('sunday-best', 1),\n",
      " ('ignatius', 1),\n",
      " ('loyola', 1),\n",
      " ('bom', 1),\n",
      " ('no—i', 1),\n",
      " ('steve', 1),\n",
      " ('hart', 1),\n",
      " ('che', 1),\n",
      " ('guevara', 1),\n",
      " ('said—i', 1),\n",
      " ('bbc', 1),\n",
      " ('dearly—i', 1),\n",
      " ('germany—and', 1),\n",
      " ('inkpad', 1),\n",
      " ('tigers—the', 1),\n",
      " ('liberation', 1),\n",
      " ('eelam—and', 1),\n",
      " ('coromandel', 1),\n",
      " ('oceania', 1),\n",
      " ('portugal', 1),\n",
      " ('vikram—as', 1),\n",
      " ('jonesville', 1),\n",
      " ('didier—hullo', 1),\n",
      " ('didier—and', 1),\n",
      " ('geezers—nigerians', 1),\n",
      " ('playboy', 1),\n",
      " ('mandelbrot', 1),\n",
      " ('were—nigerian', 1),\n",
      " ('straight—i', 1),\n",
      " ('walther', 1),\n",
      " ('p38', 1),\n",
      " ('africans—and', 1),\n",
      " ('madonna—they', 1),\n",
      " ('wednesday', 1),\n",
      " ('anti-semitism', 1),\n",
      " ('jew-haters', 1),\n",
      " ('jews', 1),\n",
      " ('ligurian', 1),\n",
      " ('columbus', 1),\n",
      " ('call—i', 1),\n",
      " ('dashrant—he', 1),\n",
      " ('staying—i', 1),\n",
      " ('rimbaud', 1),\n",
      " ('verlaine', 1),\n",
      " ('merdel', 1),\n",
      " ('reward—it', 1),\n",
      " ('upanishads', 1),\n",
      " ('hey—that', 1),\n",
      " ('mmmm', 1),\n",
      " ('lai—you', 1),\n",
      " ('wife-burning', 1),\n",
      " ('unflagged', 1),\n",
      " ('inclusion', 1),\n",
      " ('turks', 1),\n",
      " ('albanians', 1),\n",
      " ('algerians', 1),\n",
      " ('asian', 1),\n",
      " ('hong', 1),\n",
      " ('kong', 1),\n",
      " ('ugandan', 1),\n",
      " ('gnostic', 1),\n",
      " ('july', 1),\n",
      " ('delhi—on', 1),\n",
      " ('capital—krishna', 1),\n",
      " ('angola', 1),\n",
      " ('mozambique', 1),\n",
      " ('namibia', 1),\n",
      " ('sudan', 1),\n",
      " ('uganda', 1),\n",
      " ('congo', 1),\n",
      " ('t-shirt—but', 1),\n",
      " ('seiko', 1),\n",
      " ('diwali', 1),\n",
      " ('picadilly', 1),\n",
      " ('dipty', 1),\n",
      " ('edward', 1),\n",
      " ('eighth', 1),\n",
      " ('mezban', 1),\n",
      " ('cafeé', 1),\n",
      " ('california', 1),\n",
      " ('paanch', 1),\n",
      " ('ulla-maurizio-modena', 1),\n",
      " ('levis', 1),\n",
      " ('koi', 1),\n",
      " ('hor', 1),\n",
      " ('spiegel', 1),\n",
      " ('yes—ulla', 1),\n",
      " ('up—i', 1),\n",
      " ('queeg', 1),\n",
      " ('blood—modena', 1),\n",
      " ('florentine', 1),\n",
      " ('cairo', 1),\n",
      " ('andalusian', 1),\n",
      " ('gypsy', 1),\n",
      " ('schooled', 1),\n",
      " ('nigerian—the', 1),\n",
      " ('kabir', 1),\n",
      " ('iyer', 1),\n",
      " ('languages—i', 1),\n",
      " ('vikram—you', 1),\n",
      " ('perseus', 1),\n",
      " ('summer—indian', 1),\n",
      " ('wickedness—prabaker', 1),\n",
      " ('curses—may', 1),\n",
      " ('denmark—it', 1),\n",
      " ('lapierre', 1),\n",
      " ('gitanes', 1),\n",
      " ('rat-catchers', 1),\n",
      " ('cockroach', 1),\n",
      " ('mandarin', 1),\n",
      " ('curepipe', 1),\n",
      " ('scottish', 1),\n",
      " ('bmw', 1),\n",
      " ('speed-freak-arsehole-bombay-taxi-driver', 1),\n",
      " ('singa-fuckin', 1),\n",
      " ('exocet', 1),\n",
      " ('shekky', 1),\n",
      " ('ratnam—and', 1),\n",
      " ('zaïre', 1),\n",
      " ('chandrababu', 1),\n",
      " ('chandrabhai', 1),\n",
      " ('u.p', 1),\n",
      " ('bengalis', 1),\n",
      " ('kashmiris', 1),\n",
      " ('parsis', 1),\n",
      " ('fanaticism', 1),\n",
      " ('winston', 1),\n",
      " ('churchill', 1),\n",
      " ('kanoon', 1),\n",
      " ('kapoor', 1),\n",
      " ('dutt', 1),\n",
      " ('bombay—not', 1),\n",
      " ('almost-prabaker', 1),\n",
      " ('sensory', 1),\n",
      " ('deprivation', 1),\n",
      " ('insensible', 1),\n",
      " ('abdullah—i', 1),\n",
      " ('modena—that', 1),\n",
      " ('nah', 1),\n",
      " ('weird—i', 1),\n",
      " ('seagulls', 1),\n",
      " ('back—i', 1),\n",
      " ('prabaker—it', 1),\n",
      " ('impossible—prabaker', 1),\n",
      " ('shoklaji', 1),\n",
      " ('coco', 1),\n",
      " ('flipping', 1),\n",
      " ('utna', 1),\n",
      " ('pathans', 1),\n",
      " ('him—nazeer—bring', 1),\n",
      " ('well—i', 1),\n",
      " ('nangarhar', 1),\n",
      " ('afghanistan—my', 1),\n",
      " ('you—i', 1),\n",
      " ('american—a', 1),\n",
      " ('kandahar—they', 1),\n",
      " ('japanese', 1),\n",
      " ('jaa', 1),\n",
      " ('death—prabaker', 1),\n",
      " ('thirty-one', 1),\n",
      " ('goliath', 1),\n",
      " ('chandni', 1),\n",
      " ('zulfikar', 1),\n",
      " ('bhutto', 1),\n",
      " ('sindis', 1),\n",
      " ('pashtuns', 1),\n",
      " ('punjabis—against', 1),\n",
      " ('mohajirs', 1),\n",
      " ('it—karachi', 1),\n",
      " ('benazir', 1),\n",
      " ('mercedes', 1),\n",
      " ('munich', 1),\n",
      " ('austria', 1),\n",
      " ('hungary', 1),\n",
      " ('romania', 1),\n",
      " ('bulgaria', 1),\n",
      " ('firni', 1),\n",
      " ('baluchi', 1),\n",
      " ('zealand—i', 1),\n",
      " ('american—and', 1),\n",
      " ('algeria', 1),\n",
      " ('morocco', 1),\n",
      " ('marxists', 1),\n",
      " ('leninists', 1),\n",
      " ('talebs', 1),\n",
      " ('wish—i', 1),\n",
      " ('masjid-i-tuba', 1),\n",
      " ('prayer—i', 1),\n",
      " ('inter-services', 1),\n",
      " ('pro-pakistan', 1),\n",
      " ('siddiqi—you', 1),\n",
      " ('subhaan', 1),\n",
      " ('karla—that', 1),\n",
      " ('thirty-two', 1),\n",
      " ('quetta—a', 1),\n",
      " ('abdali', 1),\n",
      " ('interminable—i', 1),\n",
      " ('english-language', 1),\n",
      " ('bolan', 1),\n",
      " ('frontier', 1),\n",
      " ('dante', 1),\n",
      " ('ian', 1),\n",
      " ('donald', 1),\n",
      " ('aps', 1),\n",
      " ('kuchlaagh', 1),\n",
      " ('bostaan', 1),\n",
      " ('shaadizai', 1),\n",
      " ('gulistan', 1),\n",
      " ('qila', 1),\n",
      " ('khojak', 1),\n",
      " ('khaan', 1),\n",
      " ('kili', 1),\n",
      " ('forgetting', 1),\n",
      " ('gallic', 1),\n",
      " ('dhari', 1),\n",
      " ('baldak', 1),\n",
      " ('dabrai', 1),\n",
      " ('melkaarez', 1),\n",
      " ('16:18—pride', 1),\n",
      " ('pak', 1),\n",
      " ('paks', 1),\n",
      " ('russians—and', 1),\n",
      " ('khairo', 1),\n",
      " ('thaana', 1),\n",
      " ('humai', 1),\n",
      " ('khaarez', 1),\n",
      " ('aagha', 1),\n",
      " ('muhammad', 1),\n",
      " ('loe', 1),\n",
      " ('mullah', 1),\n",
      " ('mustafa', 1),\n",
      " ('inalillahey', 1),\n",
      " ('american-sponsored', 1),\n",
      " ('zeiss', 1),\n",
      " ('binoculars—khader', 1),\n",
      " ('indian-made', 1),\n",
      " ('bactrian', 1),\n",
      " ('wahabi', 1),\n",
      " ('mister', 1),\n",
      " ('mazar-i-sharif', 1),\n",
      " ('caligulan', 1),\n",
      " ('exacted—hajji', 1),\n",
      " ('gift—khaderbhai', 1),\n",
      " ('lower-palaeolithic', 1),\n",
      " ('face—i', 1),\n",
      " ('all-but-stone', 1),\n",
      " ('bangs', 1),\n",
      " ('saying—when', 1),\n",
      " ('bhabha', 1),\n",
      " ('atomic', 1),\n",
      " ('wolfgang', 1),\n",
      " ('persis', 1),\n",
      " ('eden', 1),\n",
      " ('kussa', 1),\n",
      " ('hada', 1),\n",
      " ('arghastan', 1),\n",
      " ('crying—i', 1),\n",
      " ('claire', 1),\n",
      " ('self-preservation', 1),\n",
      " ('whoa', 1),\n",
      " ('iddarao', 1),\n",
      " ('zaranj', 1),\n",
      " ('kunduz', 1),\n",
      " ('ak—avtomat', 1),\n",
      " ('kalashnikova—was', 1),\n",
      " ('mikhail', 1),\n",
      " ('adolph', 1),\n",
      " ('hugo', 1),\n",
      " ('sturmgewehr', 1),\n",
      " ('nazi', 1),\n",
      " ('muzzle', 1),\n",
      " ('ak', 1),\n",
      " ('egypt', 1),\n",
      " ('aks', 1),\n",
      " ('alexander', 1),\n",
      " ('huns', 1),\n",
      " ('sakas', 1),\n",
      " ('scythians', 1),\n",
      " ('mongols', 1),\n",
      " ('moghuls', 1),\n",
      " ('safavids', 1),\n",
      " ('others—i', 1),\n",
      " ('june', 1),\n",
      " ('burrows', 1),\n",
      " ('men—british', 1),\n",
      " ('maiwand', 1),\n",
      " ('roberts—do', 1),\n",
      " ('well—bobs', 1),\n",
      " ('bamiyan', 1),\n",
      " ('sepoys', 1),\n",
      " ('jalalaad—he', 1),\n",
      " ('prabaker—i', 1),\n",
      " ('prophet—no', 1),\n",
      " ('guptaji', 1),\n",
      " ('karla—for', 1),\n",
      " ('i—', 1),\n",
      " ('ak-74s', 1),\n",
      " ('kareem', 1),\n",
      " ('typically', 1),\n",
      " ('habib—to', 1),\n",
      " ('khaled—he', 1),\n",
      " ('kandeedar', 1),\n",
      " ('panjsher', 1),\n",
      " ('shaitaan', 1),\n",
      " ('satan', 1),\n",
      " ('khad', 1),\n",
      " ('najibullah', 1),\n",
      " ('bones—a', 1),\n",
      " ('food—i', 1),\n",
      " ('fortunately', 1),\n",
      " ('thirty-six', 1),\n",
      " ('zabul', 1),\n",
      " ('jalalaad—the', 1),\n",
      " ('mohmand', 1),\n",
      " ('hanif—did', 1),\n",
      " ('sixty-eight', 1),\n",
      " ('shia', 1),\n",
      " ('islam', 1),\n",
      " ('sunni', 1),\n",
      " ('village-eden', 1),\n",
      " ('place—khader', 1),\n",
      " ('karla—because', 1),\n",
      " ('pahlavi', 1),\n",
      " ('shah—the', 1),\n",
      " ('suras', 1),\n",
      " ('wind-driven', 1),\n",
      " ('ak-74s—theirs', 1),\n",
      " ('thirty-seven', 1),\n",
      " ('mazdur', 1),\n",
      " ('gul', 1),\n",
      " ('daoud', 1),\n",
      " ('zamaanat', 1),\n",
      " ('jalozai', 1),\n",
      " ('dervish', 1),\n",
      " ('aladdin', 1),\n",
      " ('abe', 1),\n",
      " ('lincoln', 1),\n",
      " ('raisins', 1),\n",
      " ('here—he', 1),\n",
      " ('shooting—i', 1),\n",
      " ('wait—i', 1),\n",
      " ('dead—suleiman', 1),\n",
      " ('jalalaad—from', 1),\n",
      " ('bombay—so', 1),\n",
      " ('urging—you', 1),\n",
      " ('bombay—made', 1),\n",
      " ('heart—i', 1),\n",
      " ('khaled—and', 1),\n",
      " ('sirf', 1),\n",
      " ('do-do-teen', 1),\n",
      " ('teen', 1),\n",
      " ('riffling', 1),\n",
      " ('shukria', 1),\n",
      " ('mainjata', 1),\n",
      " ('hamara', 1),\n",
      " ('ireland', 1),\n",
      " ('afghanistan—that', 1),\n",
      " ('here—nazeer', 1),\n",
      " ('merriweather', 1),\n",
      " ('s—i', 1),\n",
      " ('ao\\\\', 1),\n",
      " ('life—khader', 1),\n",
      " ('to—what', 1),\n",
      " ('american—his', 1),\n",
      " ('wonder—i', 1),\n",
      " ('thirty-nine', 1),\n",
      " ('patil—you', 1),\n",
      " ('lin—that', 1),\n",
      " ('wide-apart', 1),\n",
      " ('hamid—and', 1),\n",
      " ('jesuit', 1),\n",
      " ('education—salman', 1),\n",
      " ('lucy', 1),\n",
      " ('there—jeetudada', 1),\n",
      " ('khaled—even', 1),\n",
      " ('bombay—starting', 1),\n",
      " ('bombay-born', 1),\n",
      " ('pax', 1),\n",
      " ('action—i', 1),\n",
      " ('lin-brother', 1),\n",
      " ('tawdry', 1),\n",
      " ('taw-fuckin-dry', 1),\n",
      " ('khan—but', 1),\n",
      " ('bmc', 1),\n",
      " ('rani', 1),\n",
      " ('wonderland', 1),\n",
      " ('id', 1),\n",
      " ('geneva', 1),\n",
      " ('convention', 1),\n",
      " ('khan—i', 1),\n",
      " ('marathi—and', 1),\n",
      " ('question—finger', 1),\n",
      " ('beretta', 1),\n",
      " ('abdullah—to', 1),\n",
      " ('jason', 1),\n",
      " ('t.v', 1),\n",
      " ('mombadevi', 1),\n",
      " ('peace—i', 1),\n",
      " ('heart-crippled', 1),\n",
      " ('mossad', 1),\n",
      " ('someone—farid', 1),\n",
      " ('ameena', 1),\n",
      " ('strollers', 1),\n",
      " ('sicilian', 1),\n",
      " ('versova—the', 1),\n",
      " ('khaled—tariq', 1),\n",
      " ('envious', 1),\n",
      " ('maulana', 1),\n",
      " ('azad', 1),\n",
      " ('racecourse', 1),\n",
      " ('chandrashekar', 1),\n",
      " ('relations', 1),\n",
      " ('sanju', 1),\n",
      " ('baghwan', 1),\n",
      " ('pahiley', 1),\n",
      " ('shahad', 1),\n",
      " ('tabjulm', 1),\n",
      " ('atrocity', 1),\n",
      " ('saturday', 1),\n",
      " ('salman—again—to', 1),\n",
      " ('business—sanjay', 1),\n",
      " ('surprise—i', 1),\n",
      " ('villu—both', 1),\n",
      " ('s—didier', 1),\n",
      " ('mg', 1),\n",
      " ('gawd', 1),\n",
      " ('premnaath', 1),\n",
      " ('academy', 1),\n",
      " ('colouring', 1),\n",
      " ('boring', 1),\n",
      " ('a-grade', 1),\n",
      " ('signing', 1),\n",
      " ('astagfirullah', 1),\n",
      " ('zodiacs', 1),\n",
      " ('indians—only', 1),\n",
      " ('garam', 1),\n",
      " ('jarur', 1),\n",
      " ('why—', 1),\n",
      " ('lufthansa', 1),\n",
      " ('name—ulla', 1),\n",
      " ('volkenberg—to', 1),\n",
      " ('ulla—i', 1),\n",
      " ('forty-one', 1),\n",
      " ('dutchman', 1),\n",
      " ('pakistan-afghanistan', 1),\n",
      " ('kai', 1),\n",
      " ('kaipaijey', 1),\n",
      " ('hindustani', 1),\n",
      " ('malad', 1),\n",
      " ('santa', 1),\n",
      " ('cruz', 1),\n",
      " ('lakes', 1),\n",
      " ('paradoxically', 1),\n",
      " ('beings—karla', 1),\n",
      " ('naples', 1),\n",
      " ('consequently', 1),\n",
      " ('punjabi', 1),\n",
      " ('clothes—i', 1),\n",
      " ('ranjit—jeet—choudry', 1),\n",
      " ('ramprakash', 1),\n",
      " ('attentive—i', 1),\n",
      " ('gorakhpur', 1),\n",
      " ('nepal', 1),\n",
      " ('kano-walleh', 1),\n",
      " ('unadorned', 1),\n",
      " ('chaturthi', 1),\n",
      " ('solver', 1),\n",
      " ('karnataka', 1),\n",
      " ('swathes', 1),\n",
      " ('kano-bear', 1),\n",
      " ('bhagwaaaaan', 1),\n",
      " ('wow/johnny', 1),\n",
      " ('emboldened', 1),\n",
      " ('absorb', 1),\n",
      " ('together—chuha', 1),\n",
      " ('manu', 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ('harshan', 1),\n",
      " ('bichchu', 1),\n",
      " ('boy—nazeer', 1),\n",
      " ('mahmoud—', 1),\n",
      " ('maijata', 1),\n",
      " ('house—abdullah', 1),\n",
      " ('sardar', 1),\n",
      " ('malum', 1),\n",
      " ('sovereign', 1),\n",
      " ('nazeer—the', 1),\n",
      " ('no—it', 1),\n",
      " ('nothing—sanjay', 1),\n",
      " ('lanka—you', 1),\n",
      " ('fighting—tamil', 1),\n",
      " ('sinhalese', 1),\n",
      " ('others—tamil', 1),\n",
      " ('muslims—with', 1),\n",
      " ('lake—killer', 1),\n",
      " ('ooooh', 1),\n",
      " ('delhi—well', 1),\n",
      " ('idriss—khader', 1),\n",
      " ('ramesh—', 1),\n",
      " ('pieta', 1),\n",
      " ('michelangelo', 1),\n",
      " ('good—lisa', 1),\n",
      " ('now—i', 1),\n",
      " ('know—i', 1),\n",
      " ('enemy—sapna—and', 1),\n",
      " ('idriss—because', 1),\n",
      " ('mukesh', 1),\n",
      " ('bilkulfit', 1),\n",
      " ('achcha', 1),\n",
      " ('shantaram-uncle', 1)]\n"
     ]
    }
   ],
   "source": [
    "propernouns = {}\n",
    "for item in word_counts.most_common():\n",
    "    word = item[0]\n",
    "    # Word is capitalized and word appears capitalized 20% of the time\n",
    "    # Question - how to get bigrams and separate proper nouns (Shobhan Mahmoud, Mahmoud Melbaaf)\n",
    "    if (word.lower() != word) and (word_counts[word.lower()]/word_counts[word]<0.2):\n",
    "        propernouns[word.lower()] = item[1]\n",
    "propernoun_count = Counter(propernouns)\n",
    "pprint(propernoun_count.most_common())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1162b7",
   "metadata": {},
   "source": [
    "# Read word frequencies\n",
    "\n",
    "Read `word_freq_count` and `total_count` from the word frequency file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "f1b1ec9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(709588976, 1560428, 22761659, 17276)"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All lower-case\n",
    "# https://github.com/hermitdave/FrequencyWords\n",
    "# Data comes from OpenSubtitles - works better than Wikipedia. \n",
    "WORD_FREQ = 'en_full.txt'\n",
    "# https://github.com/IlyaSemenov/wikipedia-word-frequency/tree/master/results\n",
    "# Data comes from Wikipedia.\n",
    "# WORD_FREQ = 'enwiki-20190320-words-frequency.txt'\n",
    "def isascii(s):\n",
    "    \"\"\"Check if the characters in string s are in ASCII, U+0-U+7F.\"\"\"\n",
    "    return len(s) == len(s.encode())\n",
    "\n",
    "word_freq = {}\n",
    "for l in read_to_lines(WORD_FREQ):\n",
    "    lsplit = l.split(' ')\n",
    "    word = lsplit[0]\n",
    "    if isascii(word):\n",
    "        # if not '-' in word:\n",
    "            if \"\\'\" in word:\n",
    "                 word = word[0:word.index(\"\\'\")]\n",
    "            # sometime apostrophe splitting overwrites previous more popular words (list is sorted)\n",
    "            if not word in word_freq:\n",
    "                word_freq[word] = int(lsplit[1])\n",
    "word_freq_count = Counter(word_freq)\n",
    "total_count = sum(word_freq_count.values())\n",
    "\n",
    "total_count, len(word_freq), word_freq['the'], word_freq['mustn']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d22b17",
   "metadata": {},
   "source": [
    "# Read dictionary\n",
    "\n",
    "Read the dictionary of word definitions (english) into `en_dict`.\n",
    "Other choices might be better - Merriam-Webster doesn't have \"reminisce\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "a15acceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102217"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://github.com/topics/merriam-webster\n",
    "# Merriam Webster\n",
    "DICT_FILE = 'dictionary_compact.json'\n",
    "en_dict = None\n",
    "with open(DICT_FILE, 'r') as f:\n",
    "    en_dict = json.loads(f.read())\n",
    "len(en_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e134176d",
   "metadata": {},
   "source": [
    "# Find the rare words\n",
    "\n",
    "Compute the IDF of all words after trying to lemmatize correctly to find the root word and return\n",
    "`book_word_idfs` - a dictionary of word to a tuple of \n",
    " - original word\n",
    " - the version of the word which yielded the lowest IDF\n",
    " - the version of the word present in the dicrionary\n",
    " - the count of the word in the text\n",
    " - the count of the word in the frequency corpus\n",
    " - and the computed IDF\n",
    "and\n",
    "`book_nondict_words` - a dictionary of words that are not proper nouns that don't appear in the dictionary to the count in the book.\n",
    "\n",
    "\n",
    "We then filter out common words (IDF < 15)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "848c71de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reminisce None [('reminiscing', 15.421771761705486), ('reminisce', 15.189881048882121)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15138, 89)"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# needs word_freq_count, total_count and propernoun_count from global dict \n",
    "# Given `word_count`, a Counter of most common words in the document, get_top_words filters out unimportant words\n",
    "# and returns an OrderedDict of important words sorted by inverse IDF (based on the en-wiki corpus vars, word_freq_count, total_count)\n",
    "# and a `non_dict_words`, words which don't exist in en-wiki at all. \n",
    "# An important word: \n",
    "# - does not contain proper nouns\n",
    "# - does not contain numbers\n",
    "# - is at least 3 characters\n",
    "# - exists in the en-wiki dictionary\n",
    "\n",
    "# returns -1 if non-dict and -2 if not applicable, and positve idf otherwise\n",
    "\n",
    "ignore_caps = True\n",
    "def idf(word_freq_count, total_count, word):\n",
    "    # names of places and things\n",
    "    if word in propernoun_count:\n",
    "        return -2\n",
    "    # years, etc\n",
    "    if not word.isalpha():\n",
    "        return -2\n",
    "    # a, e, i, o, u\n",
    "    if len(word) < 3:\n",
    "        return -2\n",
    "    if ignore_caps and word[0] != word[0].lower():\n",
    "        return -2\n",
    "    if word.lower() not in word_freq_count:\n",
    "        if not word.lower() in en_dict:\n",
    "             return -1\n",
    "        word_freq = 1\n",
    "    word_freq = word_freq_count[word.lower()]\n",
    "    return math.log((1 + total_count)/(1 + word_freq)) + 1\n",
    "\n",
    "suffixes = ['ing', 'ly', 'less', 'ally', 'ed', 'ling', 's', 'es', 'ness', 'er', 'est', 'able', 'ful', 'ant', 'en']\n",
    "prefixes = ['semi', 'in', 'anti', 'de', 'un', 'dis', 're', 'mis']\n",
    "# manual lemmatization\n",
    "def gen_candidates(word):\n",
    "    candidates = [word]\n",
    "    if word.endswith('in'):\n",
    "        candidates.append(word+'g')\n",
    "    if word.endswith('ive'):\n",
    "        candidates.append(word[:-3]+'e')\n",
    "    if word.endswith('ier'):\n",
    "        candidates.append(word[:-3]+'y')\n",
    "    if word.endswith('ies'):\n",
    "        candidates.append(word[:-3]+'y')\n",
    "    if word.endswith('ied'):\n",
    "        candidates.append(word[:-3]+'y')\n",
    "    if word.endswith('ible'):\n",
    "        candidates.append(word[:-4]+'e')\n",
    "    if word.endswith('ent'):\n",
    "        candidates.append(word[:-3]+'ence')\n",
    "    if word.endswith('ence'):\n",
    "        candidates.append(word[:-3]+'ent')\n",
    "    if word.endswith('y'):\n",
    "        candidates.append(word[:-1])\n",
    "        candidates.append(word[:-1] + 'e')\n",
    "    for s in suffixes:\n",
    "        if word.endswith(s):\n",
    "            candidates.append(word[:-len(s)])\n",
    "            if s == 'er':\n",
    "                candidates.append(word[:-len(s)] + 'e')\n",
    "            if s == 'ly':\n",
    "                candidates.append(word[:-len(s)+1] + 'e')\n",
    "            if s == 'ing':\n",
    "                candidates.append(word[:-len(s)] + 'e')\n",
    "                if len(word[:-len(s)]) > 2 and word[:-len(s)][-1] == word[:-len(s)][-2]:\n",
    "                    candidates.append(word[:-(len(s)+1)])\n",
    "            if s == 'ed':\n",
    "                candidates.append(word[:-len(s)] + 'e')\n",
    "                if len(word[:-len(s)]) > 2 and word[:-len(s)][-1] == word[:-len(s)][-2]:\n",
    "                    candidates.append(word[:-(len(s)+1)])\n",
    "            if s == 'ness' and word[:-len(s)].endswith('i'):\n",
    "                candidates.append(word[:-(len(s)+1)] + 'y')\n",
    "            if s == 'est' and word[:-len(s)].endswith('i'):\n",
    "                candidates.append(word[:-(len(s)+1)] + 'y')\n",
    "    for p in prefixes:\n",
    "        if word.startswith(p):\n",
    "            candidates.append(word[len(p):])\n",
    "    return candidates\n",
    "\n",
    "def get_top_words(word_counts):\n",
    "    # Create a Counter() just for non-stop words preserving capitalizing\n",
    "    book_freq = {}\n",
    "    nondict_words = {}\n",
    "    for k, v in word_counts.most_common():\n",
    "        word = k\n",
    "        if word in propernoun_count:\n",
    "            continue\n",
    "        \n",
    "        cands = set([cand for c in gen_candidates(word) for cand in gen_candidates(c)])\n",
    "        candidfs = []\n",
    "        for c in cands:\n",
    "            widf = idf(word_freq_count, total_count, c)\n",
    "            if widf < 0:\n",
    "                continue\n",
    "            candidfs.append((c, widf))\n",
    "        best = (word, idf(word_freq_count, total_count, word))\n",
    "        if len(candidfs) > 0:\n",
    "            sortcands = sorted(candidfs, key=lambda x:x[1])\n",
    "            best = sortcands[0]\n",
    "            dict_cand = None\n",
    "            for x in sortcands:\n",
    "                if x[0] in en_dict:\n",
    "                    dict_cand = x[0]\n",
    "                    break\n",
    "                \n",
    "        best_cand = best[0]\n",
    "        if word.lower() == 'reminiscing':\n",
    "            print(best_cand, dict_cand, candidfs)\n",
    "        \n",
    "        word_idf = best[1]\n",
    "        if word_idf == -2:\n",
    "            continue\n",
    "        if word_idf == -1:\n",
    "            if not word.lower() in nondict_words:\n",
    "                nondict_words[word.lower()] = v\n",
    "        \n",
    "        if not word.lower() in book_freq:\n",
    "            book_freq[word.lower()] = (k, best_cand, dict_cand, v, word_freq_count[word.lower()], word_idf)\n",
    "    book_freq = OrderedDict(sorted(book_freq.items(), key=lambda x: -x[1][-1])) #Sort by last ele of value, or IDF\n",
    "    return book_freq, nondict_words\n",
    "\n",
    "book_word_idfs, book_nondict_words = get_top_words(word_counts)\n",
    "len(book_word_idfs), len(book_nondict_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "83088686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('excruciation', 'excruciation', 'excruciation', 2, 0, 21.38019645473527),\n",
       " ('claustral', 'claustral', 'claustral', 1, 0, 21.38019645473527),\n",
       " ('synonyme', 'synonyme', 'synonyme', 1, 0, 21.38019645473527),\n",
       " ('enswathed', 'enswathe', 'enswathe', 1, 0, 21.38019645473527),\n",
       " ('inevasible', 'inevasible', 'inevasible', 1, 0, 21.38019645473527),\n",
       " ('concrescence', 'concrescence', 'concrescence', 1, 0, 21.38019645473527),\n",
       " ('chrismal', 'chrismal', 'chrismal', 1, 0, 21.38019645473527),\n",
       " ('plangency', 'plangency', 'plangency', 1, 0, 21.38019645473527),\n",
       " ('splendent', 'splendent', 'splendent', 1, 0, 21.38019645473527),\n",
       " ('revulsive', 'revulse', 'revulse', 1, 0, 21.38019645473527)]"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(book_word_idfs.values())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "95f720d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1342, 15138)"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_THRESH = 16\n",
    "book_word_vocab = [w for w in book_word_idfs.values() if w[-1] >= VOCAB_THRESH] \n",
    "len(book_word_vocab), len(book_word_idfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "5feabbab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6445603576751118"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 70% of vocab words are in the english dictionary\n",
    "len([w for w in book_word_vocab if w[0] in en_dict or w[1] in en_dict]) / len(book_word_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "2a5464db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Dictionary Words: 1342\n",
      "Non Dictionary Words: 89\n",
      "Percentage Vocab Words: 7.35%\n"
     ]
    }
   ],
   "source": [
    "print(f'Vocab Dictionary Words: {len(book_word_vocab)}\\nNon Dictionary Words: {len(book_nondict_words)}\\n'+\n",
    "      f'Percentage Vocab Words: {(len(book_word_vocab) + len(book_nondict_words))*100/stats.uniq_words:0.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55120889",
   "metadata": {},
   "source": [
    "# Get a pointer from all rare words to where they appear in book\n",
    "\n",
    "Generate `vocab_postings` which is a dict from our vocab words to a list of numbers which are the indexes of the sentences in which these words occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "18a194d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28675"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_raw_sentences(lines):\n",
    "    sens = []\n",
    "    for l in lines:\n",
    "        for s in nltk.tokenize.sent_tokenize(l):\n",
    "            sens.append(s)\n",
    "    return sens\n",
    "raw_sens = get_raw_sentences(lines)\n",
    "len(raw_sens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "19a28b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_posting_list_for(raw_sentences, words):\n",
    "    posting_list_sens = defaultdict(list)\n",
    "    for i, s in enumerate(raw_sentences):\n",
    "        for w in nltk.tokenize.word_tokenize(s):\n",
    "            if not w in blacklist:\n",
    "                # Someitmes strings like ‘Your aim is off.’ don't tokenize correct.\n",
    "                if w.endswith('.'):\n",
    "                    w = w[:w.index('.')]\n",
    "                if w.endswith('…'):\n",
    "                    w = w[:w.index('…')]\n",
    "            if w.lower() in words:\n",
    "                posting_list_sens[w.lower()].append(i)\n",
    "    return posting_list_sens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "1134d001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1431, 1342)"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_vocab_raw = set([w[0] for w in book_word_vocab])\n",
    "for x in book_nondict_words:\n",
    "    book_vocab_raw.add(x)\n",
    "vocab_postings = gen_posting_list_for(raw_sens, book_vocab_raw)\n",
    "len(vocab_postings), len(book_word_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "17cbb87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_postings['guileless']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3121e6",
   "metadata": {},
   "source": [
    "# Create the final vocabulary assistance tool\n",
    "\n",
    "For all our words assemble (amongst others:\n",
    " - word\n",
    " - dictionary meaning\n",
    " - sentences in the book where they appear. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "12d6cda8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1342"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SECONDARY_LOOKUP_THRESH = 16\n",
    "all_vocab = []\n",
    "for w in book_word_vocab:\n",
    "    word = w[0].lower()\n",
    "    if word in en_dict:\n",
    "        meaning = en_dict[word]\n",
    "        root_word = None\n",
    "    elif w[2] in en_dict:\n",
    "        meaning = en_dict[w[2]]\n",
    "        root_word = w[2]\n",
    "    else:\n",
    "        meaning = ''\n",
    "        root_word = None\n",
    "    if root_word == word:\n",
    "        root_word = ''\n",
    "    extra_words = set()\n",
    "    for mw in nltk.tokenize.word_tokenize(meaning):\n",
    "        mword = mw.lower()\n",
    "        if idf(word_freq_count, total_count, mword) >= SECONDARY_LOOKUP_THRESH and mword in en_dict and mword != w[2] and mword != word:\n",
    "            extra_words.add(mword)\n",
    "    for ew in extra_words:\n",
    "        meaning = f'{meaning}\\n\\n\"{ew}\": {en_dict[ew]}'\n",
    "    if not len(vocab_postings[word]):\n",
    "        print(word)\n",
    "        continue\n",
    "    vocabrow = {\n",
    "        'word': word,\n",
    "        'root word': root_word,\n",
    "        'count in book': len(vocab_postings[word]),\n",
    "        'meaning': meaning,\n",
    "        'first_ref': vocab_postings[word][0],\n",
    "        'refs': [(x, raw_sens[x]) for x in vocab_postings[word]][:5],\n",
    "        'rarity word': root_word,\n",
    "        'rarity': w[5],\n",
    "        'rarity count': w[4]\n",
    "    }\n",
    "    all_vocab.append(vocabrow)\n",
    "len(all_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "5705b2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_vocab = sorted(all_vocab, key=lambda x:-x['count in book'])\n",
    "sorted_vocab = sorted(all_vocab, key=lambda x:x['rarity count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "ccceaa8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shantaram/shantaram_vocab.html'"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_output_path(ext, suffix = ''):\n",
    "    path = os.path.dirname(BOOK)\n",
    "    fname_noext = os.path.splitext(os.path.basename(BOOK))[0]\n",
    "    new_fname = f'{fname_noext}_vocab'\n",
    "    if suffix:\n",
    "        new_fname = f'{new_fname}_{suffix}'\n",
    "    return os.path.join(path, f'{new_fname}.{ext}')\n",
    "OUTPUT_FILE = get_output_path('html')\n",
    "OUTPUT_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "8cffa033",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv_with_suffix(suffix):\n",
    "    OUTPUT_FILE = get_output_path('csv', suffix)\n",
    "    with open(OUTPUT_FILE, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(sorted_vocab[0].keys())\n",
    "        for v in sorted_vocab:\n",
    "            writer.writerow(v.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "3809dbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_vocab = sorted(all_vocab, key=lambda x:x['rarity count'])\n",
    "write_csv_with_suffix('sortby_most_rare_first')\n",
    "sorted_vocab = sorted(all_vocab, key=lambda x:x['first_ref'])\n",
    "write_csv_with_suffix('sortby_order_of_appearance')\n",
    "sorted_vocab = sorted(all_vocab, key=lambda x:-x['count in book'])\n",
    "write_csv_with_suffix('sortby_most_common_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "67bf1b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jinja2 import Environment, FileSystemLoader, select_autoescape\n",
    "env = Environment(\n",
    "    loader=FileSystemLoader(\"templates\"),\n",
    "    autoescape=select_autoescape()\n",
    ")\n",
    "TEMPLATE = \"vocab_template.html\"\n",
    "template = env.get_template(TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "b46bc303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_html_with_jinja(suffix):\n",
    "    output = template.render(words=sorted_vocab)\n",
    "    OUTPUT_FILE = get_output_path('html', suffix)\n",
    "    with open(OUTPUT_FILE, 'w') as f:\n",
    "        f.write(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "ffed58b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_vocab = sorted(all_vocab, key=lambda x:x['rarity count'])\n",
    "write_html_with_jinja('sortby_most_rare_first')\n",
    "sorted_vocab = sorted(all_vocab, key=lambda x:x['first_ref'])\n",
    "write_html_with_jinja('sortby_order_of_appearance')\n",
    "sorted_vocab = sorted(all_vocab, key=lambda x:-x['count in book'])\n",
    "write_html_with_jinja('sortby_most_common_first')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936bcfc6",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "17e864c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('frown', 'frown', 'frown', 54, 1361, 14.16348696802581)"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_word_idfs['frown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5c1e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wordnet_lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "# wordnet_lemmatizer.lemmatize('unscathed', 'v'), [cand for c in gen_candidates('unscathed') for cand in gen_candidates(c)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "96635c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1361, 136)"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# en_dict['envelop']\n",
    "word_freq_count['frown'], word_freq_count['envelop'] #, en_dict['hotelier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d344281b",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_dict['ooze'], word_freq_count['scathe'], idf(word_freq_count, total_count, 'fascinate')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
